import streamlit as st
import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import librosa
import librosa.display
import tempfile
import shutil
from datetime import datetime
from utils.audio_separator import get_available_gpus, get_recommended_threads

matplotlib.use('Agg')

# è®¾ç½®matplotlibæ ·å¼
plt.style.use('default')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° sys.path
project_root = os.path.dirname(os.path.abspath(__file__))



sys.path.append(project_root)









# --- é…ç½® ---
SUPPORTED_EXTENSIONS = ["mp3", "wav", "flac", "ogg", "m4a"]
DEFAULT_MODEL = "htdemucs"

AVAILABLE_MODELS = ["htdemucs", "htdemucs_ft", "htdemucs_6s", "mdx", "mdx_extra", "mdx_q", "mdx_u", "hdemucs_mmi"]


OUTPUT_BASE_DIR = os.path.join(project_root, "demucs_separated_output")
os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)

# ç»˜å›¾å‡½æ•°
def plot_waveform(y, sr):
    """ç»˜åˆ¶éŸ³é¢‘æ³¢å½¢å›¾"""
    fig = plt.figure(figsize=(12, 3))
    ax = fig.add_subplot(1, 1, 1)
    ax.plot(np.linspace(0, len(y)/sr, len(y)), y)
    ax.set_title('éŸ³é¢‘æ³¢å½¢å›¾')
    ax.set_xlabel('æ—¶é—´ (ç§’)')
    ax.set_ylabel('æŒ¯å¹…')
    ax.grid(True)
    plt.tight_layout()
    return fig

def plot_melspectrogram(y, sr):
    """ç»˜åˆ¶æ¢…å°”é¢‘è°±å›¾"""
    fig = plt.figure(figsize=(12, 3))
    ax = fig.add_subplot(1, 1, 1)
    mel_spect = librosa.feature.melspectrogram(y=y, sr=sr)
    mel_spect_db = librosa.power_to_db(mel_spect, ref=np.max)




    img = librosa.display.specshow(mel_spect_db, y_axis='mel', x_axis='time', ax=ax)
    fig.colorbar(img, ax=ax, format='%+2.0f dB')
    ax.set_title('æ¢…å°”é¢‘è°±å›¾')
    plt.tight_layout()
    return fig


def process_audio_file(uploaded_file, params, status_placeholder, results_placeholder):
    """å¤„ç†å•ä¸ªéŸ³é¢‘æ–‡ä»¶"""
    status_placeholder.info("â³ æ­£åœ¨å¤„ç†éŸ³é¢‘ï¼Œè¯·ç¨å€™...")
    
    # åˆ›å»ºå”¯ä¸€çš„è¿è¡Œç›®å½•
    run_id = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
    run_output_dir = os.path.join(OUTPUT_BASE_DIR, run_id)
    os.makedirs(run_output_dir, exist_ok=True)

    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
    temp_dir = tempfile.mkdtemp(dir=run_output_dir)
    temp_input_path = os.path.join(temp_dir, uploaded_file.name)
    
    try:
        with open(temp_input_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # åŠ è½½éŸ³é¢‘ç”¨äºå¯è§†åŒ–
        y, sr = librosa.load(temp_input_path, sr=None)
        duration = librosa.get_duration(y=y, sr=sr)
        
        # è°ƒç”¨åˆ†ç¦»å‡½æ•°
        from utils.audio_separator import separate_audio
        start_time = datetime.now()
        
        success = separate_audio(
            track_path=temp_input_path,
            output_dir=os.path.join(run_output_dir, "separated"),
            model_name=params["model_name"],
            device=params["device"],
            shifts=params["shifts"],
            overlap=params["overlap"],
            no_split=params["no_split"],
            segment=params["segment"],
            two_stems=params["two_stems"],
            clip_mode=params["clip_mode"],
            mp3_bitrate=params["mp3_bitrate"],
            mp3_preset=params["mp3_preset"],
            filename=params["filename"],
            jobs=params["jobs"],
            verbose=True
        )
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        if success:
            display_results(uploaded_file, run_output_dir, params, y, sr, status_placeholder, results_placeholder, processing_time)
        else:
            status_placeholder.error("âŒ éŸ³é¢‘åˆ†ç¦»å¤±è´¥")
            
    except Exception as e:
        status_placeholder.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        st.error(traceback.format_exc())
    finally:
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)

def display_results(uploaded_file, run_output_dir, params, y, sr, status_placeholder, results_placeholder, processing_time):
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    status_placeholder.success(f"âœ… åˆ†ç¦»å®Œæˆï¼è€—æ—¶: {processing_time:.2f} ç§’")
    
    # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
    output_subdir = os.path.join(run_output_dir, "separated", params["model_name"])
    original_name = os.path.splitext(uploaded_file.name)[0]
    
    # æ ¹æ®åˆ†ç¦»æ¨¡å¼ç¡®å®šè¦æŸ¥æ‰¾çš„è¯å¹²
    stems = [params["two_stems"], f"no_{params['two_stems']}"] if params["two_stems"] else ["vocals", "drums", "bass", "other"]
    results = {}
    
    for stem in stems:
        pattern = f"{original_name}_{stem}.*"
        for f in os.listdir(output_subdir):
            if f.startswith(f"{original_name}_{stem}"):
                results[stem] = os.path.join(output_subdir, f)
                break
    
    with results_placeholder:
        # æ˜¾ç¤ºéŸ³é¢‘åˆ†æå›¾
        if y is not None and sr is not None:
            st.subheader("åŸå§‹éŸ³é¢‘åˆ†æ")
            col1, col2 = st.columns(2)
            with col1:
                try:
                    st.pyplot(plot_waveform(y, sr))
                except Exception as e:
                    st.error(f"æ³¢å½¢å›¾ç”Ÿæˆå¤±è´¥: {e}")
            with col2:
                try:
                    st.pyplot(plot_melspectrogram(y, sr))
                except Exception as e:
                    st.error(f"æ¢…å°”é¢‘è°±å›¾ç”Ÿæˆå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºåˆ†ç¦»ç»“æœ
        st.subheader("åˆ†ç¦»çš„éŸ³è½¨")
        if params["two_stems"]:
            cols = st.columns(2)
            for i, (stem, path) in enumerate(results.items()):
                with cols[i % 2]:
                    display_stem(stem, path, params["mp3_output"])
        else:
            tabs = st.tabs(["äººå£°", "é¼“å£°", "è´æ–¯", "å…¶ä»–"])
            stem_map = {"vocals": 0, "drums": 1, "bass": 2, "other": 3}
            for stem, path in results.items():
                with tabs[stem_map.get(stem, 0)]:
                    display_stem(stem, path, params["mp3_output"])

def display_stem(stem, path, is_mp3):
    """æ˜¾ç¤ºå•ä¸ªéŸ³è½¨"""
    stem_name = {
        "vocals": "äººå£°", "no_vocals": "ä¼´å¥",
        "drums": "é¼“å£°", "bass": "è´æ–¯", "other": "å…¶ä»–"
    }.get(stem, stem)
    
    st.markdown(f"**{stem_name}**")
    st.audio(path)
    
    ext = ".mp3" if is_mp3 else ".wav"
    with open(path, "rb") as f:
        st.download_button(
            label=f"ä¸‹è½½ {stem_name}{ext}",
            data=f,
            file_name=os.path.basename(path),
            mime=f"audio/{ext.lstrip('.')}"
        )

def main():
    st.set_page_config(layout="wide", page_title="éŸ³é¢‘åˆ†ç¦»ä¸é™å™ª (Demucs)")

    st.title("ğŸµ éŸ³é¢‘åˆ†ç¦»ä¸é™å™ª (Demucs)")

    
    # æ¨¡å¼é€‰æ‹©
    mode = st.radio("å¤„ç†æ¨¡å¼", ["å•æ–‡ä»¶å¤„ç†", "æ‰¹é‡å¤„ç†"], horizontal=True)
    
    if mode == "å•æ–‡ä»¶å¤„ç†":
        process_single_file_ui()
    else:
        process_batch_ui()


def process_single_file_ui():
    """å•æ–‡ä»¶å¤„ç†ç•Œé¢"""
    col1, col2 = st.columns(2)

    
    with col1:




































        st.subheader("ä¸Šä¼ ä¸å‚æ•°")
        uploaded_file = st.file_uploader("é€‰æ‹©éŸ³é¢‘æ–‡ä»¶", type=SUPPORTED_EXTENSIONS)
        params = get_separation_params()
        















    with col2:
        st.subheader("åˆ†ç¦»ç»“æœ")
        status_placeholder = st.empty()
        results_placeholder = st.container()
    
    if st.button("ğŸš€ å¼€å§‹åˆ†ç¦»", disabled=not uploaded_file):
        if uploaded_file:
            process_audio_file(uploaded_file, params, status_placeholder, results_placeholder)
        else:
            status_placeholder.warning("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")



def process_batch_ui():
    """æ‰¹é‡å¤„ç†ç•Œé¢"""
    st.warning("æ‰¹é‡å¤„ç†åŠŸèƒ½ä»åœ¨å¼€å‘ä¸­ï¼Œå½“å‰ç‰ˆæœ¬ä»…æ”¯æŒå•æ–‡ä»¶å¤„ç†")
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ‰¹é‡å¤„ç†UIçš„å®ç°
























































































































































































def get_separation_params():
    """è·å–åˆ†ç¦»å‚æ•°"""
    params = {}
    
    with st.expander("åŸºæœ¬å‚æ•°"):
        params["model_name"] = st.selectbox(
            "æ¨¡å‹", AVAILABLE_MODELS, 
            index=AVAILABLE_MODELS.index(DEFAULT_MODEL)
        )
        




        # è®¾å¤‡é€‰æ‹©
        is_cuda = torch.cuda.is_available()
        params["device"] = st.radio(
            "è®¾å¤‡", ["cuda", "cpu"], 
            index=0 if is_cuda else 1,
            horizontal=True
        )
        

        # åˆ†ç¦»æ¨¡å¼
        separation_mode = st.radio(
            "åˆ†ç¦»æ¨¡å¼", ["æ ‡å‡†å››è½¨åˆ†ç¦»", "ä»…äººå£°/ä¼´å¥åˆ†ç¦»"],
            index=1, horizontal=True
        )
        params["two_stems"] = "vocals" if separation_mode == "ä»…äººå£°/ä¼´å¥åˆ†ç¦»" else None
    
    with st.expander("é«˜çº§å‚æ•°"):
        col1, col2 = st.columns(2)
        







        with col1:
            params["shifts"] = st.slider("éšæœºç§»ä½", 0, 20, 2)
            params["overlap"] = st.slider("é‡å æ¯”ä¾‹", 0.0, 1.0, 0.5, 0.05)
            params["segment"] = st.slider("åˆ†æ®µå¤§å°(ç§’)", 1, 30, 7)
            params["jobs"] = st.slider("å¹¶è¡Œæ•°", 1, 16, get_recommended_threads())
            
        with col2:
            params["no_split"] = st.checkbox("ç¦ç”¨åˆ†æ®µå¤„ç†", False)
            params["clip_mode"] = st.selectbox("å‰Šæ³¢å¤„ç†", ["rescale", "clamp"], 0)
            
            # è¾“å‡ºæ ¼å¼
            params["mp3_output"] = st.checkbox("è¾“å‡ºä¸ºMP3", False)
            if params["mp3_output"]:
                params["mp3_bitrate"] = st.slider("MP3æ¯”ç‰¹ç‡", 64, 320, 256, 32)
                params["mp3_preset"] = st.select_slider("MP3è´¨é‡", options=[2,3,4,5,6,7], value=2)
            else:
                params["mp3_bitrate"] = 320
                params["mp3_preset"] = 2
                
            params["filename"] = "{track}_{stem}.{ext}"
    
    return params

if __name__ == "__main__":
    main()