import streamlit as st
import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import librosa
import librosa.display
import tempfile
import shutil
from datetime import datetime
from utils.audio_separator import get_available_gpus, get_recommended_threads

matplotlib.use('Agg')

# è®¾ç½®matplotlibæ ·å¼
plt.style.use('default')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° sys.path
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

# --- é…ç½® ---
SUPPORTED_EXTENSIONS = ["mp3", "wav", "flac", "ogg", "m4a"]
DEFAULT_MODEL = "htdemucs"
AVAILABLE_MODELS = ["htdemucs", "htdemucs_ft", "htdemucs_6s", "mdx", "mdx_extra", "mdx_q", "mdx_u", "hdemucs_mmi"]
OUTPUT_BASE_DIR = os.path.join(project_root, "demucs_separated_output")
os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)

# ç»˜å›¾å‡½æ•°
def plot_waveform(y, sr):
    """ç»˜åˆ¶éŸ³é¢‘æ³¢å½¢å›¾"""
    fig = plt.figure(figsize=(12, 3))
    ax = fig.add_subplot(1, 1, 1)
    ax.plot(np.linspace(0, len(y)/sr, len(y)), y)
    ax.set_title('éŸ³é¢‘æ³¢å½¢å›¾')
    ax.set_xlabel('æ—¶é—´ (ç§’)')
    ax.set_ylabel('æŒ¯å¹…')
    ax.grid(True)
    plt.tight_layout()
    return fig

def plot_melspectrogram(y, sr):
    """ç»˜åˆ¶æ¢…å°”é¢‘è°±å›¾"""
    fig = plt.figure(figsize=(12, 3))
    ax = fig.add_subplot(1, 1, 1)
    mel_spect = librosa.feature.melspectrogram(y=y, sr=sr)
    mel_spect_db = librosa.power_to_db(mel_spect, ref=np.max)
    img = librosa.display.specshow(mel_spect_db, y_axis='mel', x_axis='time', ax=ax)
    fig.colorbar(img, ax=ax, format='%+2.0f dB')
    ax.set_title('æ¢…å°”é¢‘è°±å›¾')
    plt.tight_layout()
    return fig

def process_audio_file(uploaded_file, params, status_placeholder, results_placeholder):
    """å¤„ç†å•ä¸ªéŸ³é¢‘æ–‡ä»¶"""
    # å‚æ•°éªŒè¯
    if not params["no_split"] and params["segment"] > 7.8:
        status_placeholder.error("âŒ åˆ†æ®µå¤§å°ä¸èƒ½è¶…è¿‡7.8ç§’")
        return
        
    status_placeholder.info("â³ æ­£åœ¨å¤„ç†éŸ³é¢‘ï¼Œè¯·ç¨å€™...")
    
    # åˆ›å»ºå”¯ä¸€çš„è¿è¡Œç›®å½•
    run_id = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
    run_output_dir = os.path.join(OUTPUT_BASE_DIR, run_id)
    os.makedirs(run_output_dir, exist_ok=True)

    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
    temp_dir = tempfile.mkdtemp(dir=run_output_dir)
    temp_input_path = os.path.join(temp_dir, uploaded_file.name)
    
    try:
        with open(temp_input_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # åŠ è½½éŸ³é¢‘ç”¨äºå¯è§†åŒ–
        y, sr = librosa.load(temp_input_path, sr=None)
        duration = librosa.get_duration(y=y, sr=sr)
        
        # è°ƒç”¨åˆ†ç¦»å‡½æ•°
        from utils.audio_separator import separate_audio
        start_time = datetime.now()
        
        success = separate_audio(
            track_path=temp_input_path,
            output_dir=os.path.join(run_output_dir, "separated"),
            model_name=params["model_name"],
            device=params["device"],
            shifts=params["shifts"],
            overlap=params["overlap"],
            no_split=params["no_split"],
            segment=params["segment"],
            two_stems=params["two_stems"],
            clip_mode=params["clip_mode"],
            mp3_bitrate=params["mp3_bitrate"],
            mp3_preset=params["mp3_preset"],
            filename=params["filename"],
            jobs=params["jobs"],
            verbose=True
        )
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        if success:
            display_results(uploaded_file, run_output_dir, params, y, sr, status_placeholder, results_placeholder, processing_time)
        else:
            status_placeholder.error("âŒ éŸ³é¢‘åˆ†ç¦»å¤±è´¥")
            
    except Exception as e:
        status_placeholder.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        st.error(traceback.format_exc())
    finally:
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)

def display_results(uploaded_file, run_output_dir, params, y, sr, status_placeholder, results_placeholder, processing_time):
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    status_placeholder.success(f"âœ… åˆ†ç¦»å®Œæˆï¼è€—æ—¶: {processing_time:.2f} ç§’")
    
    # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
    output_subdir = os.path.join(run_output_dir, "separated", params["model_name"])
    original_name = os.path.splitext(uploaded_file.name)[0]
    
    # æ ¹æ®åˆ†ç¦»æ¨¡å¼ç¡®å®šè¦æŸ¥æ‰¾çš„è¯å¹²
    stems = [params["two_stems"], f"no_{params['two_stems']}"] if params["two_stems"] else ["vocals", "drums", "bass", "other"]
    results = {}
    
    for stem in stems:
        pattern = f"{original_name}_{stem}.*"
        for f in os.listdir(output_subdir):
            if f.startswith(f"{original_name}_{stem}"):
                results[stem] = os.path.join(output_subdir, f)
                break
    
    with results_placeholder:
        # æ˜¾ç¤ºéŸ³é¢‘åˆ†æå›¾
        if y is not None and sr is not None:
            st.subheader("åŸå§‹éŸ³é¢‘åˆ†æ")
            col1, col2 = st.columns(2)
            with col1:
                try:
                    st.pyplot(plot_waveform(y, sr))
                except Exception as e:
                    st.error(f"æ³¢å½¢å›¾ç”Ÿæˆå¤±è´¥: {e}")
            with col2:
                try:
                    st.pyplot(plot_melspectrogram(y, sr))
                except Exception as e:
                    st.error(f"æ¢…å°”é¢‘è°±å›¾ç”Ÿæˆå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºåˆ†ç¦»ç»“æœ
        st.subheader("åˆ†ç¦»çš„éŸ³è½¨")
        if params["two_stems"]:
            cols = st.columns(2)
            for i, (stem, path) in enumerate(results.items()):
                with cols[i % 2]:
                    display_stem(stem, path, params["mp3_output"])
        else:
            tabs = st.tabs(["äººå£°", "é¼“å£°", "è´æ–¯", "å…¶ä»–"])
            stem_map = {"vocals": 0, "drums": 1, "bass": 2, "other": 3}
            for stem, path in results.items():
                with tabs[stem_map.get(stem, 0)]:
                    display_stem(stem, path, params["mp3_output"])

def display_stem(stem, path, is_mp3):
    """æ˜¾ç¤ºå•ä¸ªéŸ³è½¨"""
    stem_name = {
        "vocals": "äººå£°", "no_vocals": "ä¼´å¥",
        "drums": "é¼“å£°", "bass": "è´æ–¯", "other": "å…¶ä»–"
    }.get(stem, stem)
    
    st.markdown(f"**{stem_name}**")
    st.audio(path)
    
    ext = ".mp3" if is_mp3 else ".wav"
    with open(path, "rb") as f:
        st.download_button(
            label=f"ä¸‹è½½ {stem_name}{ext}",
            data=f,
            file_name=os.path.basename(path),
            mime=f"audio/{ext.lstrip('.')}"
        )

def main():
    st.set_page_config(layout="wide", page_title="éŸ³é¢‘åˆ†ç¦»ä¸é™å™ª (Demucs)")
    st.title("ğŸµ éŸ³é¢‘åˆ†ç¦»ä¸é™å™ª (Demucs)")
    process_single_file_ui()  # ç›´æ¥è°ƒç”¨å•æ–‡ä»¶å¤„ç†ç•Œé¢

def process_single_file_ui():
    """å•æ–‡ä»¶å¤„ç†ç•Œé¢"""
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ä¸Šä¼ ä¸å‚æ•°")
        uploaded_file = st.file_uploader("é€‰æ‹©éŸ³é¢‘æ–‡ä»¶", type=SUPPORTED_EXTENSIONS)
        
        # æ·»åŠ éŸ³é¢‘é¢„è§ˆåŠŸèƒ½
        if uploaded_file is not None:
            st.subheader("åŸå§‹éŸ³é¢‘é¢„è§ˆ")
            st.audio(uploaded_file)
            
        params = get_separation_params()
        
    with col2:
        st.subheader("åˆ†ç¦»ç»“æœ")
        status_placeholder = st.empty()
        results_placeholder = st.container()
    
    if st.button("ğŸš€ å¼€å§‹åˆ†ç¦»", disabled=not uploaded_file):
        if uploaded_file:
            process_audio_file(uploaded_file, params, status_placeholder, results_placeholder)
        else:
            status_placeholder.warning("è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")

def get_separation_params():
    """è·å–åˆ†ç¦»å‚æ•°"""
    params = {}
    
    # ä¿®æ”¹ä¸ºé»˜è®¤å±•å¼€çš„åŸºæœ¬å‚æ•°
    with st.expander("åŸºæœ¬å‚æ•°", expanded=True):  # æ·»åŠ  expanded=True
        # å›ºå®šä½¿ç”¨htdemucsæ¨¡å‹
        params["model_name"] = "htdemucs"
        
        # è®¾å¤‡é€‰æ‹©
        is_cuda = torch.cuda.is_available()
        params["device"] = st.radio(
            "è®¾å¤‡", ["cuda", "cpu"], 
            index=0 if is_cuda else 1,
            horizontal=True
        )
        
        # å›ºå®šä½¿ç”¨äººå£°/ä¼´å¥åˆ†ç¦»æ¨¡å¼
        params["two_stems"] = "vocals"
    
    # ä¿®æ”¹ä¸ºé»˜è®¤å±•å¼€çš„é«˜çº§å‚æ•°
    with st.expander("é«˜çº§å‚æ•°", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            params["shifts"] = st.slider(
                "éšæœºç§»ä½", 0, 20, 2,
                help="å¢åŠ éšæœºç§»ä½æ¬¡æ•°å¯ä»¥æé«˜åˆ†ç¦»è´¨é‡ä½†ä¼šå»¶é•¿å¤„ç†æ—¶é—´ã€‚0è¡¨ç¤ºç¦ç”¨ï¼Œæ¨èå€¼2-5"
            )
            # ä¿®æ”¹overlapå‚æ•°ï¼Œé™åˆ¶æœ€å¤§å€¼ä¸º0.99
            params["overlap"] = st.slider(
                "é‡å æ¯”ä¾‹", 0.0, 0.99, 0.5, 0.05,
                help="éŸ³é¢‘ç‰‡æ®µä¹‹é—´çš„é‡å æ¯”ä¾‹(0-0.99)ã€‚å¢åŠ å¯ä»¥æé«˜è´¨é‡ä½†ä¼šä½¿ç”¨æ›´å¤šå†…å­˜"
            )
            
            # ä¿®æ”¹segmentå‚æ•°ä¸ºæ•´æ•°ç±»å‹
            max_segment = 7  # æ”¹ä¸ºæ•´æ•°7
            params["segment"] = st.slider(
                "åˆ†æ®µå¤§å°(ç§’)", 1, max_segment, min(7, max_segment), 1,
                help=f"å°†éŸ³é¢‘åˆ†å‰²æˆå°æ®µå¤„ç†ï¼Œæœ‰åŠ©äºèŠ‚çœæ˜¾å­˜ã€‚æœ€å¤§ä¸èƒ½è¶…è¿‡{max_segment}ç§’"
            )
            
            params["jobs"] = st.slider(
                "å¹¶è¡Œæ•°", 1, 16, get_recommended_threads(),
                help="å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°ã€‚è‡ªåŠ¨è®¾ç½®ä¸ºCPUæ ¸å¿ƒæ•°-2ï¼Œå¢åŠ å¯åŠ å¿«å¤„ç†ä½†ä¼šå ç”¨æ›´å¤šèµ„æº"
            )
            
        with col2:
            # ç¦ç”¨åˆ†æ®µå¤„ç†é€‰é¡¹éœ€è¦ä¸segmentå‚æ•°è”åŠ¨
            params["no_split"] = st.checkbox(
                "ç¦ç”¨åˆ†æ®µå¤„ç†", False,
                help="ç¦ç”¨éŸ³é¢‘åˆ†æ®µå¤„ç†ï¼Œå¯èƒ½æé«˜è´¨é‡ä½†ä¼šæ˜¾è‘—å¢åŠ æ˜¾å­˜å ç”¨"
            )
            
            # å¦‚æœç¦ç”¨åˆ†æ®µå¤„ç†ï¼Œåˆ™å¼ºåˆ¶ä½¿ç”¨CPU
            if params["no_split"]:
                st.warning("âš ï¸ ç¦ç”¨åˆ†æ®µå¤„ç†å°†ä½¿ç”¨CPUå¤„ç†ä»¥é¿å…å†…å­˜é—®é¢˜")
                params["device"] = "cpu"  # å¼ºåˆ¶ä½¿ç”¨CPU
                params["segment"] = None  # è®¾ç½®ä¸ºNoneè¡¨ç¤ºä¸åˆ†å‰²
            
            params["clip_mode"] = st.selectbox(
                "å‰Šæ³¢å¤„ç†", ["rescale", "clamp"], 0,
                help="é¿å…å‰Šæ³¢çš„ç­–ç•¥ï¼šrescale(åŠ¨æ€ç¼©æ”¾æ•´ä¸ªä¿¡å·)æˆ–clamp(ç›´æ¥é™åˆ¶æŒ¯å¹…)"
            )
            
            # è¾“å‡ºæ ¼å¼
            params["mp3_output"] = st.checkbox(
                "è¾“å‡ºä¸ºMP3", False,
                help="å°†è¾“å‡ºè½¬æ¢ä¸ºMP3æ ¼å¼ä»¥å‡å°æ–‡ä»¶å¤§å°"
            )
            if params["mp3_output"]:
                params["mp3_bitrate"] = st.slider(
                    "MP3æ¯”ç‰¹ç‡", 64, 320, 256, 32,
                    help="MP3ç¼–ç æ¯”ç‰¹ç‡(kbps)ï¼Œå€¼è¶Šé«˜éŸ³è´¨è¶Šå¥½ä½†æ–‡ä»¶è¶Šå¤§"
                )
                params["mp3_preset"] = st.select_slider(
                    "MP3è´¨é‡", options=[2,3,4,5,6,7], value=2,
                    help="MP3ç¼–ç è´¨é‡é¢„è®¾ï¼š2(æœ€é«˜è´¨é‡)åˆ°7(æœ€å¿«é€Ÿåº¦)"
                )
            else:
                params["mp3_bitrate"] = 320
                params["mp3_preset"] = 2
                
            params["filename"] = "{track}_{stem}.{ext}"
    
    return params

if __name__ == "__main__":
    main()
    # Add this right after torch import to prevent Streamlit inspection issues
    torch.classes.__path__ = None  # Disable Streamlit's attempt to inspect torch.classes